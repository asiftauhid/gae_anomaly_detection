{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Graph Construction\n",
    "\n",
    "Load data, split train/test, and build k-NN graphs for GAE training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: pandex/trace\n",
      "k-NN neighbors: 3\n",
      "Test size: 0.3\n",
      "Output: data/\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"../e2-master\"\n",
    "SCENARIO = \"pandex\"\n",
    "PROVIDER = \"trace\"\n",
    "\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "K_NEIGHBORS = 5\n",
    "OUTPUT_DIR = \"data\"\n",
    "\n",
    "BASE_PATH = Path(DATASET_PATH) / SCENARIO / PROVIDER\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Dataset: {SCENARIO}/{PROVIDER}\")\n",
    "print(f\"k-NN neighbors: {K_NEIGHBORS}\")\n",
    "print(f\"Test size: {TEST_SIZE}\")\n",
    "print(f\"Output: {OUTPUT_DIR}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ProcessAll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 272,376 processes\n",
      "Shape: (272376, 300)\n"
     ]
    }
   ],
   "source": [
    "process_file = BASE_PATH / \"ProcessAll.csv.gz\"\n",
    "\n",
    "with gzip.open(process_file, 'rt') as f:\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "print(f\"Loaded {len(df):,} processes\")\n",
    "print(f\"Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process IDs: 272,376\n",
      "Feature matrix: (272376, 299)\n",
      "Sparsity: 98.0%\n"
     ]
    }
   ],
   "source": [
    "id_column = df.columns[0]\n",
    "feature_columns = [col for col in df.columns if col != id_column]\n",
    "\n",
    "process_ids = df[id_column].values\n",
    "X = df[feature_columns].values.astype(np.float32)\n",
    "\n",
    "print(f\"Process IDs: {len(process_ids):,}\")\n",
    "print(f\"Feature matrix: {X.shape}\")\n",
    "print(f\"Sparsity: {(X == 0).mean():.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ground Truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace_pandex_micro.csv: 82 attacks\n",
      "trace_pandex_drakon2.csv: 25 attacks\n",
      "trace_pandex_drakon.csv: 47 attacks\n",
      "\n",
      "Total attacks: 153\n",
      "Normal: 272,351 (100.0%)\n",
      "Attack: 25 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "attack_uuids = set()\n",
    "gt_files = list(BASE_PATH.glob(f\"{PROVIDER}_{SCENARIO}_*.csv\"))\n",
    "\n",
    "for gt_file in gt_files:\n",
    "    gt_df = pd.read_csv(gt_file)\n",
    "    if 'uuid' in gt_df.columns:\n",
    "        uuids = gt_df['uuid'].unique()\n",
    "        attack_uuids.update(uuids)\n",
    "        print(f\"{gt_file.name}: {len(uuids)} attacks\")\n",
    "\n",
    "y = np.array([1 if pid in attack_uuids else 0 for pid in process_ids], dtype=np.int32)\n",
    "\n",
    "print(f\"\\nTotal attacks: {len(attack_uuids)}\")\n",
    "print(f\"Normal: {(y == 0).sum():,} ({(y == 0).mean():.1%})\")\n",
    "print(f\"Attack: {(y == 1).sum():,} ({(y == 1).mean():.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split (Unsupervised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (normal only):\n",
      "  Samples: 190,645\n",
      "  Attack: 0\n",
      "\n",
      "Test (normal + all attacks):\n",
      "  Samples: 81,731\n",
      "  Normal: 81,706\n",
      "  Attack: 25\n"
     ]
    }
   ],
   "source": [
    "normal_mask = (y == 0)\n",
    "anomaly_mask = (y == 1)\n",
    "\n",
    "X_normal = X[normal_mask]\n",
    "y_normal = y[normal_mask]\n",
    "ids_normal = process_ids[normal_mask]\n",
    "\n",
    "X_anomaly = X[anomaly_mask]\n",
    "y_anomaly = y[anomaly_mask]\n",
    "ids_anomaly = process_ids[anomaly_mask]\n",
    "\n",
    "X_train, X_test_normal, y_train, y_test_normal, ids_train, ids_test_normal = train_test_split(\n",
    "    X_normal, y_normal, ids_normal,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "X_test = np.vstack([X_test_normal, X_anomaly])\n",
    "y_test = np.concatenate([y_test_normal, y_anomaly])\n",
    "ids_test = np.concatenate([ids_test_normal, ids_anomaly])\n",
    "\n",
    "print(\"Train (normal only):\")\n",
    "print(f\"  Samples: {len(X_train):,}\")\n",
    "print(f\"  Attack: {(y_train == 1).sum()}\")\n",
    "\n",
    "print(\"\\nTest (normal + all attacks):\")\n",
    "print(f\"  Samples: {len(X_test):,}\")\n",
    "print(f\"  Normal: {(y_test == 0).sum():,}\")\n",
    "print(f\"  Attack: {(y_test == 1).sum():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build k-NN Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train graph (k=3):\n",
      "  [1/4] Normalizing features... (0.2s)\n",
      "  [2/4] Finding k=3 neighbors for 190,645 nodes... (745.5s)\n",
      "  [3/4] Building edge list... (0.0s)\n",
      "  [4/4] Removing duplicates... (2.1s)\n",
      "  Graph built: 190,645 nodes, 1,328,345 edges (total: 747.8s)\n",
      "\n",
      "Building test graph (k=3):\n",
      "  [1/4] Normalizing features... (0.1s)\n",
      "  [2/4] Finding k=3 neighbors for 81,731 nodes... (99.1s)\n",
      "  [3/4] Building edge list... (0.0s)\n",
      "  [4/4] Removing duplicates... (0.8s)\n",
      "  Graph built: 81,731 nodes, 567,521 edges (total: 100.1s)\n"
     ]
    }
   ],
   "source": [
    "from utils.graph_construction import create_graph_data\n",
    "\n",
    "print(f\"Building train graph (k={K_NEIGHBORS}):\")\n",
    "train_graph = create_graph_data(X_train, y_train, k_neighbors=K_NEIGHBORS)\n",
    "\n",
    "print(f\"\\nBuilding test graph (k={K_NEIGHBORS}):\")\n",
    "test_graph = create_graph_data(X_test, y_test, k_neighbors=K_NEIGHBORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/:\n",
      "  train_graph.pt, test_graph.pt\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(OUTPUT_DIR)\n",
    "\n",
    "torch.save(train_graph, output_path / \"train_graph.pt\")\n",
    "torch.save(test_graph, output_path / \"test_graph.pt\")\n",
    "\n",
    "print(f\"Saved to {OUTPUT_DIR}/:\")\n",
    "print(f\"  train_graph.pt, test_graph.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly",
   "language": "python",
   "name": "anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
