{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rare Pattern Mining\n",
    "\n",
    "Mine rare feature combinations from test data and build rare pattern graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Libraries imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: data/\n",
      "Output: rare_patterns/\n",
      "Pattern range: 10-1000 processes\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"data\"\n",
    "OUTPUT_DIR = \"rare_patterns\"\n",
    "\n",
    "MIN_COUNT = 10\n",
    "MAX_COUNT = 1000\n",
    "MAX_PATTERN_LENGTH = 2\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Data: {DATA_DIR}/\")\n",
    "print(f\"Output: {OUTPUT_DIR}/\")\n",
    "print(f\"Pattern range: {MIN_COUNT}-{MAX_COUNT} processes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test graph:\n",
      "  Nodes: 81,731\n",
      "  Edges: 888,913\n",
      "  Features: 299\n",
      "  Attack nodes: 25\n"
     ]
    }
   ],
   "source": [
    "test_graph = torch.load(Path(DATA_DIR) / \"test_graph.pt\", weights_only=False)\n",
    "\n",
    "print(f\"Test graph:\")\n",
    "print(f\"  Nodes: {test_graph.num_nodes:,}\")\n",
    "print(f\"  Edges: {test_graph.num_edges:,}\")\n",
    "print(f\"  Features: {test_graph.num_node_features}\")\n",
    "print(f\"  Attack nodes: {(test_graph.y == 1).sum().item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Features to Transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting one-hot features to transactions...\n",
      "Created 81,731 transactions\n",
      "Total features: 299\n",
      "Avg active features per process: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting one-hot features to transactions...\")\n",
    "\n",
    "test_features = test_graph.x.cpu().numpy()\n",
    "test_transactions = []\n",
    "\n",
    "for i in range(len(test_features)):\n",
    "    transaction = set()\n",
    "    for j in range(test_features.shape[1]):\n",
    "        if test_features[i, j] > 0.5:\n",
    "            transaction.add(f\"feat_{j}\")\n",
    "    test_transactions.append(transaction)\n",
    "\n",
    "print(f\"Created {len(test_transactions):,} transactions\")\n",
    "print(f\"Total features: {test_features.shape[1]}\")\n",
    "print(f\"Avg active features per process: {np.mean([len(t) for t in test_transactions]):.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mine Rare Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Patterns in 10-1000 processes\n",
      "Support: [0.012%, 1.22%]\n",
      "\n",
      "Mining itemsets with Apriori algorithm\n",
      "   Transactions: 81,731\n",
      "   Support range: [0.00012235259571031799, 0.0122352595710318]\n",
      "   Max itemset size: 2\n",
      "   Counting 1-itemsets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning transactions: 100%|██████████| 81731/81731 [00:00<00:00, 794459.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1-itemsets: 162 frequent (support >= 0.00012235259571031799)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking 2-itemsets: 100%|██████████| 81731/81731 [01:48<00:00, 755.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2-itemsets: 2,876 frequent\n",
      "Total itemsets found: 3,746\n",
      "\n",
      "Rare itemsets (support in [0.00012235259571031799, 0.0122352595710318]):\n",
      "   Count: 2,782\n",
      "   Rarest: 0.0001 support\n",
      "   Least rare: 0.0122 support\n",
      "\n",
      "Generating association rules\n",
      "   Min confidence: 0.5\n",
      "Generated 2,896 rules\n",
      "\\nFound 2,782 rare feature combinations\n"
     ]
    }
   ],
   "source": [
    "from utils.apriori import mine_rare_patterns\n",
    "\n",
    "n_total = len(test_transactions)\n",
    "min_support = MIN_COUNT / n_total\n",
    "max_support = MAX_COUNT / n_total\n",
    "\n",
    "print(f\"Target: Patterns in {MIN_COUNT}-{MAX_COUNT} processes\")\n",
    "print(f\"Support: [{min_support*100:.3f}%, {max_support*100:.2f}%]\")\n",
    "print()\n",
    "\n",
    "rare_itemsets, _ = mine_rare_patterns(\n",
    "    test_transactions,\n",
    "    min_support=min_support,\n",
    "    max_support=max_support,\n",
    "    max_length=MAX_PATTERN_LENGTH,\n",
    "    min_confidence=0.5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\\\nFound {len(rare_itemsets):,} rare feature combinations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Top Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 rarest combinations:\n",
      " 1. [feat_184]\n",
      "    Appears in 10 processes (0.012%)\n",
      " 2. [feat_96]\n",
      "    Appears in 10 processes (0.012%)\n",
      " 3. [feat_78]\n",
      "    Appears in 10 processes (0.012%)\n",
      " 4. [feat_184, feat_8]\n",
      "    Appears in 10 processes (0.012%)\n",
      " 5. [feat_184, feat_3]\n",
      "    Appears in 10 processes (0.012%)\n",
      " 6. [feat_13, feat_30]\n",
      "    Appears in 10 processes (0.012%)\n",
      " 7. [feat_17, feat_22]\n",
      "    Appears in 10 processes (0.012%)\n",
      " 8. [feat_12, feat_192]\n",
      "    Appears in 10 processes (0.012%)\n",
      " 9. [feat_17, feat_192]\n",
      "    Appears in 10 processes (0.012%)\n",
      "10. [feat_200, feat_43]\n",
      "    Appears in 10 processes (0.012%)\n"
     ]
    }
   ],
   "source": [
    "if len(rare_itemsets) > 0:\n",
    "    print(f\"Top 10 rarest combinations:\")\n",
    "    for i, (itemset, support) in enumerate(rare_itemsets[:10], 1):\n",
    "        count = int(support * n_total)\n",
    "        features = \", \".join(sorted(list(itemset)))\n",
    "        print(f\"{i:2d}. [{features}]\")\n",
    "        print(f\"    Appears in {count:,} processes ({support*100:.3f}%)\")\n",
    "else:\n",
    "    print(\"No patterns found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Pattern Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rare Pattern Distribution Analysis:\n",
      "   Normal processes:\n",
      "      Avg rare patterns: 2.29 ± 21.34\n",
      "      % with rare patterns: 15.7%\n",
      "   Attack processes:\n",
      "      Avg rare patterns: 43.60 ± 74.90\n",
      "      % with rare patterns: 84.0%\n",
      "   Attacks have MORE rare patterns (good signal!)\n"
     ]
    }
   ],
   "source": [
    "from utils.rare_patterns import analyze_rare_pattern_distribution\n",
    "\n",
    "if len(rare_itemsets) > 0:\n",
    "    y_true = test_graph.y.cpu().numpy()\n",
    "    \n",
    "    stats = analyze_rare_pattern_distribution(\n",
    "        test_transactions,\n",
    "        rare_itemsets,\n",
    "        y_true\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Rare Pattern Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building rare pattern graph...\n",
      "Building rare graph (fully connected mode)\n",
      "   Processing 2,782 rare patterns...\n",
      "Rare graph created:\n",
      "   Nodes: 81,731\n",
      "   Edges: 9,056,962\n",
      "\\nRare graph created:\n",
      "  Nodes: 81,731\n",
      "  Edges: 9,056,962\n"
     ]
    }
   ],
   "source": [
    "from utils.rare_patterns import build_rare_graph_fully_connected\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "if len(rare_itemsets) > 0:\n",
    "    print(\"Building rare pattern graph...\")\n",
    "    \n",
    "    rare_graph_test = build_rare_graph_fully_connected(\n",
    "        rare_itemsets,\n",
    "        test_transactions,\n",
    "        test_graph.x,\n",
    "        test_graph.y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\nRare graph created:\")\n",
    "    print(f\"  Nodes: {rare_graph_test.num_nodes:,}\")\n",
    "    print(f\"  Edges: {rare_graph_test.num_edges:,}\")\n",
    "else:\n",
    "    print(\"No patterns found, creating empty graph...\")\n",
    "    \n",
    "    rare_graph_test = Data(\n",
    "        x=test_graph.x,\n",
    "        edge_index=torch.zeros((2, 0), dtype=torch.long),\n",
    "        y=test_graph.y\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to rare_patterns/:\n",
      "  rare_graph_test.pt (9,056,962 edges)\n"
     ]
    }
   ],
   "source": [
    "torch.save(rare_graph_test, Path(OUTPUT_DIR) / \"rare_graph_test.pt\")\n",
    "\n",
    "print(f\"Saved to {OUTPUT_DIR}/:\")\n",
    "print(f\"  rare_graph_test.pt ({rare_graph_test.num_edges:,} edges)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare pattern mining complete:\n",
      "- Mined 2,782 rare patterns\n",
      "- Built graph with 9,056,962 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"Rare pattern mining complete:\")\n",
    "print(f\"- Mined {len(rare_itemsets):,} rare patterns\")\n",
    "print(f\"- Built graph with {rare_graph_test.num_edges:,} edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly",
   "language": "python",
   "name": "anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
